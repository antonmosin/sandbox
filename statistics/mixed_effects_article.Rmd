---
title: "Mixed-Effects"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
source('mixed_effects_article.R')

options(dplyr.summarise.inform = FALSE)
setwd("~/Desktop/library/courses/statistics")
```


# Introduction
Replicate the [article](https://medium.com/convoy-tech/cracking-correlated-observations-in-a-b-tests-with-mixed-effect-models-80a63027444e)

# Validate the chosen distrubitons.

## 1. Number of generated tasks per user.
The author used exponential distrubition with \labmda = 5 to simulate number of tasks created by a user.

```{r}
set.seed(2928932)
N_USERS <- 5000
RATE <- 5
tasks_per_user <- round(rexp(N_USERS, rate=RATE))
qplot(tasks_per_user)
summary(tasks_per_user)
```

Doesn't look like the one in the article. Maybe he meant $1/\labmda$?

```{r}
set.seed(2928932)
N_USERS <- 5000
RATE <- 1/5
tasks_per_user <- round(rexp(N_USERS, rate=RATE))
qplot(tasks_per_user)
summary(tasks_per_user)
```

It looks better, but now the majority users generated one task, not zero.

Let's try geometric distribution instead that should be more appropriate for a count varialbe.
```{r}
set.seed(2928932)
N_USERS <- 5000
PROB <- 1/3
tasks_per_user <- rgeom(N_USERS, prob=PROB)
qplot(tasks_per_user)
summary(tasks_per_user)
```

Great, now the mode is at 0 and we get a few power users with > 10 tasks.

## 2. Prior on the user probability to complete a task.

Tne author picked Beta(3, 2).

```{r}
set.seed(2928932)
prior_prob_complet <- rbeta(n=N_USERS, shape1 = 3, shape2 = 2)
qplot(prior_prob_complet)
summary(prior_prob_complet)
```
Looks correct.

# Run the simulation

For each user
1. Randomly assign them to treatment or control.
2. Draw from a distribution to determine how many tasks the user will create over the test period.
3. Draw from a distribution to determine the user’s “base rate” for how often they mark their tasks on time.
4. Sample from a Bernoulli distribution (with the user rate) to determine for each task if it was completed on-time or not.


Check % of false positives (should not be higher than \alpha)

```{r}
set.seed(39393)
N_USERS <- 5000
GAMMA_PROB <- 1/3
ALPHA = 3
BETA = 2
res <- run_simulation(n_sims=100,
                      n_users = N_USERS,
                      gamma_prob = GAMMA_PROB,
                      prior_alpha = ALPHA,
                      prior_beta = BETA,
                      test_alpha=0.05)
```


```{r}
mean(res$naive_test)
mean(res$mixed_model)
```
